- entree vide dans Catalog: refuser

- ameliorer le log lorsqu'un client accede a un Hole qui n'a pas les donnees

- mauvais utilisateur => segfault client

- si noeud de stockage recoit un block mutable avec une version > 0 et que
  aucune autre version n'existe -> discard. ca resoud un probleme genre
  open dir, add, close dir mais entre temps le dir a ete destroyed.
- dans Journal, stocker tous les immutable en parallele, puis stocker les
  mutable car les storage nodes vont recuper certain immutable (genre Access)
  pour verifier la validiter de Object par exemple.

- setter un bit a un dans MutableBlock si history est active pour ce
  block.

- dans le nest: discard (si plus de place) les blocs non modifies

- mettre dans la conf du reseau le Byzantine tolerance fonction du type
  de block physique.

- faire en sorte que meme lorsque nos serveurs ne fonctionnent pas, les
  donnees restent accessibles (important). par contre il faut que lorsqu'un
  user est supprime, il ne puisse plus du tout acceder (invalidate)
- la self-encryption (qui fait gagner masse de place) devrait etre activee
  par defaut. et si le mec ne veut pas, il change! cela dit si chaque
  bloc de donnees contient l'owner ou bien un lien vers l'object, alors
  ca ne sert a rien car on ne gagnera jamais de place.

- contacter UPMC/Central

- du -sh dans Infinit ne marche pas

- ajouter first/next/previous/last etc.

- pour un Catalog, il faut que le Porcupine garde dans l'arbre le nombre
  d'entrees pour facilement retrouve par index!

- balance dans insert/delete
- collecter les blocs qui se font derouilles avant le Seal

- coder un Handle pour PorcupineLoader

- il est possible qu'on ait une merde: en deletant une entree, on delete
  le block, donc on met a jour les left/right nodules pour qu'ils ne pointent
  plus sur le nodule deleted. donc on load les right/left. malheureusement,
  si plus tard une operation load le(s) parent(s) qui veulent loader le meme
  nodule, le systeme ne va pas faire le lien et le meme nodule va etre loade
  deux fois. pour resoudre ce probleme:
  -> soit on garde dans Porcupine un set Address/Nodule* des nodules loades
     dans le system.
  -> soit on load et unload immediatement et ensuite ca va dans un cache
     qui lui aura une limite de taille max (donc c'est mieux car system-wide)
     et (i) il ecrit sur disque si modifie et plus de place (ii) on a plus
     le probleme en question puisqu'on reload lorsque necessaire.
     => dans ce cas c'est Journal qui va s'occuper de ca. il recoit des blocks
        les garde pour un certain temps (ou si la taille max est atteinte)
        et les decharge si necessaire: appellant Depot si les blocs ont
        ete modifies.
     => donc chaque load doit etre suivi d'un unload une fois le block utilise
     => a noter que puisque les scopes gerent deja les multiples acces, journal
        peut considerer que ses blocs sont uniques. ainsi si un block est
	demande, celui-ci peut tout simplement le refiler sans se soucier de
	quoi que ce soit (attention tout de meme aux objects qui devrait
	surement reset les states etc. puisque sealed i.e faire que Consistent
	= Clean a la limite)
===> en fait j'opte pour l'option: on stocke temporairement sur le disque
  les blocs (comme un cache) jusqu'a ce que le bloc soit ferme. ainsi on
  evite 3 choses: (i) pas besoin de calculer l'adresse du bloc a chaque modif
  pour que si le cache le vire il puisse etre stocke tout en ayant le porcupine
  qui le reference correctement (ii) on a pas besoin de se faire chier a
  regulierement decharge sur le reseau pour liberer de la RAM et (iii) si
  on decharge un block qui est ensuite re-modifie, pour faire les choses
  proprement il faudrait delete l'ancienne version temporaire
  -> petit probleme: pour decharger sur le disque, il faut tout de meme un
     identifiant de reference: adresse de stockage ou autre.

- check footprint in hole::Push (XXX)

- pour simplifier la suppression de blocs: on peut linker chaque bloc
  a l'Object et dans Object mettre une permission suppression.

- mettre les attributs dans un autre block? voire seulement si ca depasse
  un nombre d'entrees/footprint?

- pour les liens freres: c'est la merde car lorsque l'on charge un block
  il faut genre trouver le frere en remontant et redescandant dans
  la hierarchie: pas pratique.
  -> peut etre autant faire direct un parcours via cette methode?

- Block a une Footprint classe qui contient la taille et un state.
 -> si l'instance est modifie, on ivnalide le footprint. et quand on appelle
    Footprint(), c'est recompute que si necessaire.

- attentiion les attributs dans Object ne peuvent pas etre infinis -> ou
  a mettre dans un CHB
- make Catalog, Data, Link and Access derive CHB

- idee: par defaut, taux de repli = nb de hosts
 -> ainsi les donnees sont tjs accessibles
 -> puis quand un certain seuil est atteint on propose a l'admin de changer
- faire un test avec gros fichiers sans Porcupine -> mettre dans Wiki
- coder Porcupine dans elle/
  - virer les Null sur les callbacks
  - eventuellement: changer les vecteurs en map dans quill/seam
- resoudre probleme avec les size_t sur 64-bit -> warnings

#
# ---------- porcupine --------------------------------------------------------
#

- Contents<T> contient un Porcupine dependant de T
- chaque Contents<T> a un comportement specifique

[Data]

- operations:
  - Write
  - Read
  - Adjust
  - Capacity
- Contents contient un Porcupine<Offset, Data>: indexe par l'offset de la donnee
- comportement:
  - Read:
    1) locate entree qui contient l'offset de depart
    2) utiliser le lien frere pour passer au suivant jusqu'a ce que toutes les
       donnees soient lues ou le fin des donnees soient atteintes
  - Write:
    1) locate entree qui contient l'offset
      a) si elle n'existe pas
        i) si assez de place a gauche, a droite ou sur les deux:
          -> distribuer les ecritures sur les blocs voisins
        ii) sinon:
          -> creer un ou plusieurs nouveaux blocs (GCD sur la taille totale
             a inserer et la taille nominale d'un block: a faire a la main
             surement)
          -> inserer le ou les blocs
      b) si elle existe
        - ecraser les donnees existantes en passant aux blocs suivant via
          le lien frere
    2) continuer avec la suite des donnees en utilisant soit le cas: le
       block existe ou pas

[Catalog]

- operations:
  - Add
  - Exist
  - Lookup
  - Consult
  - Rename
  - Remove
  - Capacity
- Contents contient un Porcupine<Slice, Catalog>: indexe par le nom de l'entree
- comportement:
  - Add:
    1) locate le catalog pour ce slice
    2) si il reste de la place...
      i) sur le catalog courant: ajouter
      ii) sur un voisin: ajouter
      iii) sinon prendre le plus gros, ajouter et splitter
  - Exist
    1) locate entree
  - Lookup
    1) locate entree
  - Consult
    1) locate node pour l'index de debut: LINEAIRE (au pire faire remonter dans
       l'arbre le nombre d'entrees par catalogue pour pouvoir facilement retrouver)
    2) ensuite utiliser le lien frere pour passer les entrees jusqu'a l'index
       de fin.
  - Rename
    1) locate entree
  - Remove
    1) locate entree
    2) la supprimer
    3) si le catalogue devient trop petit, redistribuer sur les noeuds voisins
       (si possible)

[Reference]

- operations:
  - Bind
  - Resolve
  - Capacity
- Contents contient une Reference



!WARNING!: il faut essayer de garantir une taille mini des blocs, sauf dans le
  cas d'un unique block avec peu de donnees: cela dit ca c'est complique puisque
  rien que les blocs de noeuds peuvent ne contenir qu'une entree!

=> l'idee en tout cas c'est d'avoir des blocs de taille moyenne
=> il faut que les limites soient bien choisies pour que le split donne naissance
   a deux blocs dont la taille est superieure a la limite basse. meme chose
   quand on remove une entree directory, le bloc devient trop petit, il faut
   qu'il puisse etre redistribuer sur les voisins sans split (sans si il est
   le dernier).
